{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.optim\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "import os, sys, json, glob\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import skimage.io\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import cv2\n",
    "import models.wiener_model as wm\n",
    "import models.dataset as ds\n",
    "from PIL import Image\n",
    "import helper as hp\n",
    "\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mwaller-fuoco\u001b[m  Fri Jan 21 16:37:05 2022\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 91'C\u001b[m, \u001b[1m\u001b[32m100 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 9956\u001b[m / \u001b[33m11176\u001b[m MB | \u001b[1m\u001b[30mkyrollos\u001b[m(\u001b[33m9945M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m6M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA TITAN X (Pascal)   \u001b[m |\u001b[1m\u001b[31m 61'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    4\u001b[m / \u001b[33m12196\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA TITAN Xp           \u001b[m |\u001b[1m\u001b[31m 88'C\u001b[m, \u001b[1m\u001b[32m 99 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m11973\u001b[m / \u001b[33m12196\u001b[m MB | \u001b[1m\u001b[30mtiffany\u001b[m(\u001b[33m11969M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA TITAN Xp           \u001b[m |\u001b[31m 32'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    4\u001b[m / \u001b[33m12196\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training code for 2D & 3D spatially-varying deconvolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('--data_type', default='2D')\n",
    "parser.add_argument('--network', default='multiwiener') #'wiener' or 'unet' or 'multiwiener'\n",
    "parser.add_argument('--id', default='') #some identifier\n",
    "parser.add_argument('--loss_type', default='l1') \n",
    "parser.add_argument('--device', default='0') \n",
    "parser.add_argument('--psf_num', default=9, type=int)\n",
    "parser.add_argument('--psf_ds', default=0.75, type=float)\n",
    "parser.add_argument('--epochs', default=10000, type=int)\n",
    "parser.add_argument('--lr', default=1e-4, type=float) \n",
    "parser.add_argument('--load_path',default=None)\n",
    "parser.add_argument('--save_checkponts',default=True)\n",
    "\n",
    "args = parser.parse_args(''.split())\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 3D-UNet multiwiener\n",
    "registered_psfs_path = '../data/multiWienerPSFStack_40z_aligned.mat'\n",
    "psfs = scipy.io.loadmat(registered_psfs_path)\n",
    "psfs=psfs['multiWienerPSFStack_40z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing 9 psfs\n"
     ]
    }
   ],
   "source": [
    "if args.data_type == '3D':\n",
    "    if args.network=='wiener' or args.network=='unet':\n",
    "        psfs=hp.pre_process_psfs(psfs)[:,:,4]\n",
    "        Ks=np.ones((32,1,1))\n",
    "        print('choosing 1 psfs')\n",
    "\n",
    "    elif args.network=='multiwiener':\n",
    "        Ks=np.ones((args.psf_num,32,1,1))\n",
    "        if args.psf_num==9:\n",
    "            print('choosing 9 psfs')\n",
    "            psfs=hp.pre_process_psfs(psfs)\n",
    "    else:\n",
    "        print('invalid network')\n",
    "    psfs = hp.downsize_psf(psfs)\n",
    "else: #2D\n",
    "    if args.network=='wiener' or args.network=='unet':\n",
    "        psfs=hp.pre_process_psfs_2d(psfs)[:,:,4, 0]\n",
    "        Ks= 1.\n",
    "        print('choosing 1 psfs')\n",
    "\n",
    "    elif args.network=='multiwiener':\n",
    "        Ks=np.ones((args.psf_num,1,1))\n",
    "        if args.psf_num==9:\n",
    "            print('choosing 9 psfs')\n",
    "            psfs=hp.pre_process_psfs_2d(psfs)[...,0]\n",
    "            psfs = psfs.transpose(2,0,1)\n",
    "    else:\n",
    "        print('invalid network')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset and dataloader for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of images 22126\n",
      "training images: 17700 testing images: 4426\n"
     ]
    }
   ],
   "source": [
    "down_size = ds.downsize(ds=args.psf_ds)\n",
    "to_tensor = ds.ToTensor()\n",
    "add_noise=ds.AddNoise()\n",
    "\n",
    "if args.data_type == '3D':\n",
    "    filepath_gt = '/home/kyrollos/LearnedMiniscope3D/Data3D/Training_data_all/' \n",
    "else:\n",
    "    filepath_gt = '/home/kyrollos/LearnedMiniscope3D/Data/Target/'\n",
    "    filepath_meas = '/home/kyrollos/LearnedMiniscope3D/Data/Train/'\n",
    "\n",
    "\n",
    "filepath_all=glob.glob(filepath_gt+'*')\n",
    "random.Random(8).shuffle(filepath_all)\n",
    "print('total number of images',len(filepath_all))\n",
    "total_num_images = len(filepath_all)\n",
    "num_test = 0.2 # 20% test\n",
    "filepath_train=filepath_all[0:int(total_num_images*(1-num_test))]\n",
    "filepath_test=filepath_all[int(total_num_images*(1-num_test)):]\n",
    "\n",
    "print('training images:', len(filepath_train), \n",
    "      'testing images:', len(filepath_test))\n",
    "\n",
    "if args.data_type == '3D':\n",
    "    dataset_train = ds.MiniscopeDataset(filepath_train, transform = transforms.Compose([down_size,add_noise,to_tensor]))\n",
    "    dataset_test = ds.MiniscopeDataset(filepath_test, transform = transforms.Compose([down_size,add_noise,to_tensor]))\n",
    "else:\n",
    "    dataset_train = ds.MiniscopeDataset_2D(filepath_train, filepath_meas, transform = transforms.Compose([ds.crop2d(),ds.ToTensor2d()]))\n",
    "    dataset_test = ds.MiniscopeDataset_2D(filepath_test, filepath_meas, transform = transforms.Compose([ds.crop2d(),ds.ToTensor2d()]))\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=1,\n",
    "                        shuffle=True, num_workers=1)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=1,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "device = 'cuda:0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.data_type == '3D':\n",
    "    from models.unet3d import Unet\n",
    "    unet_model = Unet(n_channel_in=args.psf_num, n_channel_out=1, residual=False, down='conv', up='tconv', activation='selu').to(device)\n",
    "\n",
    "    if args.network == 'multiwiener' or args.network == 'wiener':\n",
    "        wiener_model=wm.WienerDeconvolution3D(psfs,Ks).to(device)\n",
    "        model=wm.MyEnsemble(wiener_model,unet_model)\n",
    "    else:\n",
    "        model = unet_model\n",
    "else: #2D\n",
    "    from models.unet import Unet\n",
    "    if args.network == 'multiwiener':\n",
    "        num_in_channels = args.psf_num\n",
    "    else:\n",
    "        num_in_channels = 1\n",
    "        \n",
    "    \n",
    "    unet_model = Unet(n_channel_in=num_in_channels, n_channel_out=1, residual=False, down='conv', up='tconv', activation='selu').to(device)\n",
    "\n",
    "    if args.network == 'multiwiener' or args.network == 'wiener':\n",
    "        wiener_model=wm.WienerDeconvolution3D(psfs,Ks).to(device)\n",
    "        model=wm.MyEnsemble(wiener_model,unet_model)\n",
    "    else:\n",
    "        model = unet_model\n",
    "\n",
    "    \n",
    "if args.load_path is not None:\n",
    "    model.load_state_dict(torch.load('saved_data/'+args.load_path,map_location=torch.device(device)))\n",
    "    print('loading saved model')\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.save_checkponts == True:\n",
    "    filepath_save = 'saved_data/' +\"_\".join((list(vars(args).values()))[0:5]) + \"/\"\n",
    "\n",
    "    if not os.path.exists(filepath_save):\n",
    "        os.makedirs(filepath_save)\n",
    "\n",
    "    with open(filepath_save + 'args.json', 'w') as fp:\n",
    "        json.dump(vars(args), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_loss=27e7\n",
    "\n",
    "for itr in range(0,args.epochs):\n",
    "    for i_batch, sample_batched in enumerate(dataloader_train):\n",
    "        optimizer.zero_grad()\n",
    "        #out = model(sample_batched['meas'].repeat(1,32,1,1)[...,18:466,4:644].unsqueeze(0).to(device))\n",
    "        if args.network=='unet' and args.data_type == '3D':\n",
    "            out = model(sample_batched['meas'].repeat(1,1,32,1,1).to(device))\n",
    "        else:\n",
    "            out = model(sample_batched['meas'].to(device))\n",
    "\n",
    "        if args.loss_type=='l1':\n",
    "            loss = loss_fn(out, sample_batched['im_gt'].to(device))\n",
    "        else:\n",
    "            loss = loss_fn(out, sample_batched['im_gt'].to(device))+(1- ms_ssim( out[0], sample_batched['im_gt'][0].to(device), data_range=1, size_average=False))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch: ', itr, ' batch: ', i_batch, ' loss: ', loss.item(), end='\\r')\n",
    "\n",
    "        #break \n",
    "    if args.data_type == '3D':\n",
    "        out_np = np.max(out.detach().cpu().numpy()[0,0],0)\n",
    "        gt_np = np.max(sample_batched['im_gt'].detach().cpu().numpy()[0,0],0)\n",
    "        meas_np = np.max(sample_batched['meas'].detach().cpu().numpy()[0,0],0)\n",
    "    else:\n",
    "        out_np = out.detach().cpu().numpy()[0][0]\n",
    "        gt_np = sample_batched['im_gt'].detach().cpu().numpy()[0][0]\n",
    "        meas_np = sample_batched['meas'].detach().cpu().numpy()[0][0]\n",
    "\n",
    "    f, ax = plt.subplots(1, 3, figsize=(15,15))\n",
    "    ax[0].imshow(gt_np)\n",
    "    ax[1].imshow(meas_np)\n",
    "    ax[2].imshow(out_np)\n",
    "    plt.show()\n",
    "\n",
    "    if args.save_checkponts == True:\n",
    "        torch.save(model.state_dict(), filepath_save + 'model_noval.pt')\n",
    "    \n",
    "    if itr%1==0:\n",
    "        total_loss=0\n",
    "        for i_batch, sample_batched in enumerate(dataloader_test):\n",
    "            with torch.no_grad():\n",
    "                if args.network=='unet' and args.data_type == '3D':\n",
    "                    out = model(sample_batched['meas'].repeat(1,1,32,1,1).to(device))\n",
    "                else:\n",
    "                    out = model(sample_batched['meas'].to(device))\n",
    "                if args.loss_type=='l1':\n",
    "                    loss = loss_fn(out, sample_batched['im_gt'].to(device))\n",
    "                else:\n",
    "                    loss = loss_fn(out, sample_batched['im_gt'].to(device))+(1- ms_ssim( out[0], sample_batched['im_gt'][0].to(device), data_range=1, size_average=False))\n",
    "                \n",
    "                \n",
    "                total_loss+=loss.item()\n",
    "                \n",
    "                print('loss for testing set ',itr,' ',i_batch, total_loss)\n",
    "                \n",
    "            #break\n",
    "        \n",
    "        if args.save_checkponts == True:\n",
    "            im_gt = Image.fromarray((np.clip(gt_np/np.max(gt_np),0,1)*255).astype(np.uint8))\n",
    "            im = Image.fromarray((np.clip(out_np/np.max(out_np),0,1)*255).astype(np.uint8))\n",
    "            im.save(filepath_save + str(itr) + '.png')\n",
    "            im_gt.save(filepath_save + 'gt.png')\n",
    "        \n",
    "        \n",
    "        if total_loss<best_loss:\n",
    "            best_loss=total_loss\n",
    "\n",
    "            # save checkpoint\n",
    "            if args.save_checkponts == True:\n",
    "                torch.save(model.state_dict(), filepath_save + 'model.pt')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_np = np.max(out.detach().cpu().numpy()[0,0],0)\n",
    "gt_np = np.max(sample_batched['im_gt'].detach().cpu().numpy()[0,0],0)\n",
    "meas_np = np.max(sample_batched['meas'].detach().cpu().numpy()[0,0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_np = out.detach().cpu().numpy()[0][0]\n",
    "gt_np = sample_batched['im_gt'].detach().cpu().numpy()[0][0]\n",
    "meas_np = sample_batched['meas'].detach().cpu().numpy()[0][0]\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(15,15))\n",
    "ax[0].imshow(gt_np)\n",
    "ax[1].imshow(meas_np)\n",
    "ax[2].imshow(out_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
